## Session 4: Seasonal ARIMA(p,d,q)x(P,D,Q) Modelling and Forecasting

#### “All models are false, but some are useful.” George Box (1979)

### Aim: Identify (and fit) at least 2 plausible Seasonal ARIMA(p,d,q)(P,D,Q) models for the Atur (No. of unemployed people registered by INEM) time series.

### **Atur:** Spanish Monthly Unemployment Time Series

The data comes from the website of the Ministry of Employment and Social Security of Spain (https://expinterweb.mites.gob.es/series/) in the section Statistics / Labor Market / Registered Labor Movement / Main Series and correspond to the number of individuals registered as unemployed in INEM offices.

### I. Model Identification

#### Exploratory data analysis

Plot the time series

```{r}
serie=window(ts(read.table("atur.dat")/1000,start=1996,freq=12),start=1996)
print(round(serie,0))
```

```{r}
plot(serie,main="Paro registrado en España (miles de personas)")
abline(v=1990:2020,col=4,lty=3)
text(1996:2019+0.5,5000,1996:2019,cex=0.8)
```

Comments? 1996-2000, –2004, —2008, 2010, 2012, 2013-2016

#### Transformation to stationarity

**Is Variance constant?**

```{r}
##Plot de medias-varianzas
m=apply(matrix(serie,nr=12),2,mean)
v=apply(matrix(serie,nr=12),2,var)
plot(m,v,xlab="Medias anuales",ylab="Varianzas anuales",main="serie")
abline(lm(v~m),col=2,lty=3,lwd=2)
```

```{r}
##ZOOM
plot(m,v,xlab="Medias anuales",ylab="Varianzas anuales",main="serie",ylim=c(0,40000))
abline(lm(v~m), col=2, lty=3,lwd=2)
```

```{r}
boxplot(serie~floor(time(serie)))
```

Clearly, an increasing variance confirmed. Thus a log transformation applied to stabilize the variance!

```{r}
lnserie=log(serie)
plot(lnserie)
```

```{r}
boxplot(lnserie~floor(time(lnserie)))
```

Then, variance seemingly constant!

**Is seasonality present?**

Decomposition plot: For description only

```{r}

plot(decompose(lnserie))
```
The type of trend and seasonal behavior more clearly seen!

```{r}
monthplot(lnserie)
```


Thus: seasonality present, with s=12 months. Clearly in summer more employment! Feb and Nov more unemployment!!

#### Eliminate the seasonality applying a seasonal difference $(1-B^{12})\log(Xt)$


```{r}
d12lnserie=diff(lnserie,12)
plot(d12lnserie)
abline(h=0)
abline(h=mean(d12lnserie),col=2)
```

**Is the mean constant?**

Apparently not! Thus apply a regular difference

```{r}
d1d12lnserie=diff(d12lnserie,1)
plot(d1d12lnserie)
abline(h=0)
```

Hmmm, not clear if constant mean. At this point we need to make a decision. We have two options:
  
  A) Consider that d1d12lnserie has already constant mean, or
  
  B) Non-constant mean yet and so we try another regular difference, as follows:


```{r}
d1d1d12lnserie=diff(d1d12lnserie,1)
plot(d1d1d12lnserie)
abline(h=0)
```


Now, d1d1d12lnserie clearly has a constant mean (Mean =0).

Check for possible overdifferencing: how the variances behave!

```{r}
var(lnserie)
var(d12lnserie)
var(d1d12lnserie)
var(d1d1d12lnserie)
```


Which series do you choose to fit an ARIMA model? d112lnserie or d1d1d12lnserie? Fit ARIMA models for the chosen time series.

‘Load’ the function ‘validation’: used later

```{r}
#################Validation#################################
validation=function(model,dades){
  s=frequency(get(model$series))
  resid=model$residuals
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  #Residuals plot
  plot(resid,main="Residuals")
  abline(h=0)
  abline(h=c(-3*sd(resid),3*sd(resid)),lty=3,col=4)
  #Square Root of absolute values of residuals (Homocedasticity)
  scatter.smooth(sqrt(abs(resid)),main="Square Root of Absolute residuals",
                 lpars=list(col=2))
  
  #Normal plot of residuals
  qqnorm(resid)
  qqline(resid,col=2,lwd=2)
  
  ##Histogram of residuals with normal curve
  hist(resid,breaks=20,freq=FALSE)
  curve(dnorm(x,mean=mean(resid),sd=sd(resid)),col=2,add=T)
  
  
  #ACF & PACF of residuals
  par(mfrow=c(1,2))
  acf(resid,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #ACF & PACF of square residuals 
  par(mfrow=c(1,2))
  acf(resid^2,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid^2,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #Ljung-Box p-values
  par(mar=c(2,2,1,1))
  tsdiag(model,gof.lag=7*s)
  cat("\n--------------------------------------------------------------------\n")
  print(model)
  
  #Stationary and Invertible
  cat("\nModul of AR Characteristic polynomial Roots: ", 
      Mod(polyroot(c(1,-model$model$phi))),"\n")
  cat("\nModul of MA Characteristic polynomial Roots: ",
      Mod(polyroot(c(1,model$model$theta))),"\n")
  
  #Model expressed as an MA infinity (psi-weights)
  psis=ARMAtoMA(ar=model$model$phi,ma=model$model$theta,lag.max=36)
  names(psis)=paste("psi",1:36)
  cat("\nPsi-weights (MA(inf))\n")
  cat("\n--------------------\n")
  print(psis[1:20])
  
  #Model expressed as an AR infinity (pi-weights)
  pis=-ARMAtoMA(ar=-model$model$theta,ma=-model$model$phi,lag.max=36)
  names(pis)=paste("pi",1:36)
  cat("\nPi-weights (AR(inf))\n")
  cat("\n--------------------\n")
  print(pis[1:20])
  
  ## Add here complementary tests (use with caution!)
  ##---------------------------------------------------------
  cat("\nNormality Tests\n")
  cat("\n--------------------\n")
 
  ##Shapiro-Wilks Normality test
  print(shapiro.test(resid(model)))

  suppressMessages(require(nortest,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(ad.test(resid(model)))
  
  suppressMessages(require(tseries,quietly=TRUE,warn.conflicts=FALSE))
  ##Jarque-Bera test
  print(jarque.bera.test(resid(model)))
  
  cat("\nHomoscedasticity Test\n")
  cat("\n--------------------\n")
  suppressMessages(require(lmtest,quietly=TRUE,warn.conflicts=FALSE))
  ##Breusch-Pagan test
  obs=get(model$series)
  print(bptest(resid(model)~I(obs-resid(model))))
  
  cat("\nIndependence Tests\n")
  cat("\n--------------------\n")
  
  ##Durbin-Watson test
  print(dwtest(resid(model)~I(1:length(resid(model)))))
  
  ##Ljung-Box test
  cat("\nLjung-Box test\n")
  print(t(apply(matrix(c(1:4,(1:4)*s)),1,function(el) {
    te=Box.test(resid(model),type="Ljung-Box",lag=el)
    c(lag=(te$parameter),statistic=te$statistic[[1]],p.value=te$p.value)})))
  

  #Sample ACF vs. Teoric ACF
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  acf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample ACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36),ylim=c(-1,1), 
       type="h",xlab="Lag",  ylab="", main="ACF Teoric")
  abline(h=0)
  
  #Sample PACF vs. Teoric PACF
  pacf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample PACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36, pacf=T),ylim=c(-1,1),
       type="h", xlab="Lag", ylab="", main="PACF Teoric")
  abline(h=0)
  par(mfrow=c(1,1))
}
################# Fi Validation #################################
```

### II. Model Fitting and Validation

#### A) Construct feasible models based on d1d12lnserie 

P(ACF) of d1d12lnserie and identify possible models

```{r}
par(mfrow=c(1,2))
acf(d1d12lnserie,ylim=c(-1,1),col=c(2,rep(1,11)),lwd=2,lag.max=72)
pacf(d1d12lnserie,ylim=c(-1,1),col=c(rep(1,11),2),lwd=2,lag.max=72)
par(mfrow=c(1,1))
```

In regular part: ARMA(1,1) since both decay; or AR(8).

In seasonal part: Clearly MA(2) or AR(2).

We decide to fit 2 models for d1d12lnserie:

Model 1: SMA(2); ARMA(1,1) regular, and Model 2: SMA(2); AR(8) regular.


#### Model 1

$ARMA(1,0,1)(0,0,2)_{12}$ for stationary d1d12lnserie ($W_t=(1-B)(1-B^{12})\log X_t$)

```{r}
(mod1=arima(d1d12lnserie,order=c(1,0,1),seasonal=list(order=c(0,0,2),period=12)))
```

Mean non-significant. Now, fit ARIMA directly to lnserie

$ARIMA(1,1,1)(0,1,2)_{12}$ for Non-Stationary lnserie 

```{r}
(mod1=arima(lnserie,order=c(1,1,1),seasonal=list(order=c(0,1,2),period=12)))
```

SMA2 coef. non significant; re-do only with without SMA1

```{r}
(mod1=arima(lnserie,order=c(1,1,1),seasonal=list(order=c(0,1,1),period=12)))
```


#### Validate Model 1

```{r}
dades=d1d12lnserie
model=mod1
validation(model,dades)
```

#### Model 2

$ARIMA(8,0,0)(0,0,2)_{12}$ for assumed stationary d1d12lnserie ($W_t=(1-B)(1-B^{12})\log X_t$)

```{r}
(mod2=arima(d1d12lnserie,order=c(8,0,0),seasonal=list(order=c(0,0,2),period=12)))
```

Mean non-significant. Now, fit ARIMA directly to lnserie

$ARIMA(8,1,0)(0,1,2)_{12}$ for lnserie

```{r}
(mod2=arima(lnserie,order=c(8,1,0),seasonal=list(order=c(0,1,2),period=12)))
```
SMA2 coef. non significant; re-do only with without SMA1

```{r}
(mod2=arima(lnserie,order=c(8,1,0),seasonal=list(order=c(0,1,1),period=12)))
```
```{r}
(mod2b=arima(lnserie,order=c(7,1,0),seasonal=list(order=c(0,1,1),period=12)))
```
ar8 non-signicant but do not eliminate because AIC increments!

#### Validate Model 2

```{r}
dades=d1d12lnserie
model=mod2
validation(model,dades)
```

### B) Alternative Model 3 for series d1d1d12lnserie with constant mean( = 0)

P(ACF) for series d1d1d12lnserie

```{r}
par(mfrow=c(1,2))
acf(d1d1d12lnserie,ylim=c(-1,1),col=c(2,rep(1,11)),lwd=2,lag.max=72)
pacf(d1d1d12lnserie,ylim=c(-1,1),col=c(rep(1,11),2),lwd=2,lag.max=72)
par(mfrow=c(1,1))
```
Clealy an SMA(1) and MA(1)

#### Model 3 for d1d1d12lnserie: ARIMA(0,2,1)x(0,1,1)12 (the so-called airline model)

$ARIMA(0,2,1)(0,1,1)_{12}$ for NON-Stationary lnserie 

```{r}
(mod3=arima(lnserie,order=c(0,2,1),seasonal=list(order=c(0,1,1),period=12)))
```
#### Validate model 3

```{r}
dades=d1d1d12lnserie
model=mod3
validation(model,dades)
```


Similar validation “behavior” to model 1

### III. Forecasting

#### Forecasting: Model 1

**Is model 1 stable?**

```{r}
########### Model stability (without constant!!!) ###############

ultim=c(2018,12)
pdq=c(1,1,1)
PDQ=c(0,1,1)

serie2=window(serie,end=ultim)
lnserie2=log(serie2)
serie1=window(serie,end=ultim+c(1,0))
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12)))
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12)))
```
#### Thus stable (significance, sign and magnitud)

#### Out-of-sample prediction

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)


ts.plot(serie,tl,tu,pr,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2014,2020),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2014:2020,lty=3,col=4)
```

Compute metrics for forecasting capability

```{r}
(previs=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))

obs=window(serie,start=ultim)

mod.RMSE1=sqrt(sum((obs-pr)^2)/12)
mod.MAE1=sum(abs(obs-pr))/12
mod.RMSPE1=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE1=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE1,"MAE"=mod.MAE1,"RMSPE"=mod.RMSPE1,"MAPE"=mod.MAPE1)

mCI1=mean(tu-tl)

cat("\nMean Length CI: ",mCI1)
```


```{r}
##### Long-term predictions with the complete model ######

pred=predict(modA,n.ahead=12)
pr<-ts(c(tail(lnserie1,1),pred$pred),start=ultim+c(1,0),freq=12)
se<-ts(c(0,pred$se),start=ultim+c(1,0),freq=12)

#Intervals
tl1<-ts(exp(pr-1.96*se),start=ultim+c(1,0),freq=12)
tu1<-ts(exp(pr+1.96*se),start=ultim+c(1,0),freq=12)
pr1<-ts(exp(pr),start=ultim+c(1,0),freq=12)

ts.plot(serie,tl1,tu1,pr1,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2015,2021),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2015:2021,lty=3,col=4)
```

```{r}
(previs1=window(cbind(tl1,pr1,tu1),start=ultim+c(1,0)))
```


#### Forecasting: Model 2

**Is model 2 stable?**


```{r}
###########  Model stability (without constant!!!) ###############
ultim=c(2018,12)
pdq=c(8,1,0)
PDQ=c(0,1,1)

serie2=window(serie,end=ultim)
lnserie2=log(serie2)
serie1=window(serie,end=ultim+c(1,0))
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12)))
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12)))
```

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)


ts.plot(serie,tl,tu,pr,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2014,2020),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2014:2020,lty=3,col=4)
```

```{r}
(previs=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))

obs=window(serie,start=ultim)

mod.RMSE2=sqrt(sum((obs-pr)^2)/12)
mod.MAE2=sum(abs(obs-pr))/12
mod.RMSPE2=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE2=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE2,"MAE"=mod.MAE2,"RMSPE"=mod.RMSPE2,"MAPE"=mod.MAPE2)
mCI2=mean(tu-tl)

cat("\nMean Length CI: ",mCI2)
```

```{r}
##### Long-term predictions with the complete model ######


pred=predict(modA,n.ahead=12)
pr<-ts(c(tail(lnserie1,1),pred$pred),start=ultim+c(1,0),freq=12)
se<-ts(c(0,pred$se),start=ultim+c(1,0),freq=12)

#Intervals
tl1<-ts(exp(pr-1.96*se),start=ultim+c(1,0),freq=12)
tu1<-ts(exp(pr+1.96*se),start=ultim+c(1,0),freq=12)
pr1<-ts(exp(pr),start=ultim+c(1,0),freq=12)

ts.plot(serie,tl1,tu1,pr1,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2015,2021),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2015:2021,lty=3,col=4)
```

```{r}
(previs2=window(cbind(tl1,pr1,tu1),start=ultim+c(1,0)))
```

#### Forecasting: Model 3

**Is model 3 stable?**

```{r}
###########  Model stability (without constant!!!) ###############
ultim=c(2018,12)
pdq=c(0,2,1)
PDQ=c(0,1,1)

serie2=window(serie,end=ultim)
lnserie2=log(serie2)
serie1=window(serie,end=ultim+c(1,0))
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12)))
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12)))
```

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)


ts.plot(serie,tl,tu,pr,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2014,2020),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2014:2020,lty=3,col=4)
```

```{r}
(previs=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))

obs=window(serie,start=ultim)

mod.RMSE3=sqrt(sum((obs-pr)^2)/12)
mod.MAE3=sum(abs(obs-pr))/12
mod.RMSPE3=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE3=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE3,"MAE"=mod.MAE3,"RMSPE"=mod.RMSPE3,"MAPE"=mod.MAPE3)

mCI3=mean(tu-tl)

cat("\nMean Length CI: ",mCI3)
```

```{r}
#####  Long-term predictions with the complete model  ######


pred=predict(modA,n.ahead=12)
pr<-ts(c(tail(lnserie1,1),pred$pred),start=ultim+c(1,0),freq=12)
se<-ts(c(0,pred$se),start=ultim+c(1,0),freq=12)

#Intervals
tl1<-ts(exp(pr-1.96*se),start=ultim+c(1,0),freq=12)
tu1<-ts(exp(pr+1.96*se),start=ultim+c(1,0),freq=12)
pr1<-ts(exp(pr),start=ultim+c(1,0),freq=12)

ts.plot(serie,tl1,tu1,pr1,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=c(2015,2021),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=2015:2021,lty=3,col=4)
```

```{r}
(previs3=window(cbind(tl1,pr1,tu1),start=ultim+c(1,0)))
```
```{r}
resul=matrix(c(AIC(mod1),BIC(mod1),mod.RMSE1,mod.MAE1,mod.RMSPE1,mod.MAPE1,mCI1,AIC(mod2),BIC(mod2),mod.RMSE2,mod.MAE2,mod.RMSPE2,mod.MAPE2,mCI2,AIC(mod3),BIC(mod3),mod.RMSE3,mod.MAE3,mod.RMSPE3,mod.MAPE3,mCI3),nc=7,byrow=T)

dimnames(resul)[[2]]=c("AIC","BIC","RMSE","MAE","RMSPE","MAPE","meanCI")
row.names(resul)=c("ARIMA(1,1,1)(0,1,1)12","ARIMA(8,1,0)(0,1,1)12","ARIMA(0,2,1)(0,1,1)12")
resul
```

