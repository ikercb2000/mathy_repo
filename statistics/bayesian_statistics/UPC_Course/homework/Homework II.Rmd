---
title: "Homework 2 Bayesian Analysis"
author: "Iker Cesar Caballero Bragagnini"
date: "2023-02-23"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Homework 2

#### 1) How would you carry out an analysis to compare the number of points that are scored in a NBA’s match with the number of points that are scored in an ACB’s match? Specify which statistical model you would use and which would be the priori in both ACB and NBA games.

In this case we can carry the analysis by proposing a bayesian model for the distribution of points in both the NBA and the ACB and for the prior distribution of each one, leading to two different bayesian models with the same statistical model.

When comparing two distributions, we could use bayesian inference methods in order to check the difference in means, variances and others through bayesian hypothesis testing or through credibile intervals. However, the aim is not to infer on the parameters but just to do a simple comparison between the distributions of both leagues, so we stick to this.

In this case, the statistical model that we will use will be the following:

$$
M=\{Poiss(\lambda_{team}); \lambda_{team}\in \mathbb{R}^+\}
$$
The statistical model assumes that the number of points are generated by a normal distribution with unknown parameter $\lambda$ in the positive real line $\mathbb{R}^+$. Now we can derive two prior distributions according to our prior knowledge and exercise of the matter: one for the NBA and other for the ACB.

For the NBA prior, we can suppose that there are very few matches where a team e ends up with less than 80 points, as the NBA is characterized for being a very offensive and dynamic league with great scoring talents (and relatively poor defense). However, it is also quite uncommon to see a team scoring more than 120 points, due to the fact that time constraints offensive talents or defensive failures.

Hence, the interval of points in a average match would be [160,240], which means that the average value of points cannot be outside this interval. Hence, we would consider a prior distribution such that $E(X)=\frac{240+160}{2}=200$. In this case, the prior distribution is assumed to be a Gamma distribution with $\alpha=800$ and $\beta=4$ , fixing a high $\beta$ because it is the parameter that controls variance and we know that probability of the mean scoring being near or at the extremes of [160,240] should be virtually zero or at least impressively small.

$$
M_{Bayes}^{NBA}=\{Poiss(\lambda_{nba}); \lambda_{nba}\in \mathbb{R}^+;\pi(\lambda_{nba})\} \quad where \quad \pi(\lambda_{nba})\sim Gamma(\alpha=800,\beta=4)
$$

When it comes to the ACB, we can argue that the offensive capability plays a weaker role, and both tactics and defense become more important in scoring. Due to this fact, we would expect an average game to have a lower interval than an average game in the NBA. From our own experience, it is very unlikely to see a team that scores less than 70 points, but it is very uncommon to see an impressively high scoring like 110 points.

Hence, the interval of points in a match would be [140,220], which means that the average value of points cannot be outside this interval. Hence, we would consider a prior distribution such that $E(X)=\frac{220+140}{2}=190$. In this case, the prior distribution is assumed to be a Gamma distribution with $\alpha=760$ and $\beta=4$ , fixing a high $\beta$ because it is the parameter that controls variance and we know that probability of the mean scoring being near or at the extremes of [140,220] should be virtually zero or at least impressively small.

$$
M_{Bayes}^{ACB}=\{Poiss(\lambda_{acb}); \lambda_{acb}\in \mathbb{R}^+;\pi(\lambda_{acb})\} \quad where \quad \pi(\lambda_{acb})\sim Gamma(\alpha=760,\beta=4)
$$

#### 2) In the data file Basquet.txt you will find the total number of points of 20 matches taken randomly from ACB and 20 taken from NBA. Plot on the same graph the priori, the likelihood and the posteriori distribution for each type of match.

In order to plot the graphs for each of the distributions asked, we first need to download the required packages and the data from "basquet.csv". We also fix a random seed (666).

```{r,message=FALSE}
library("ggplot2")
library(dplyr)
library(tidyr)
library(purrr)
library(gridExtra)
set.seed(666)
```

We now use simulation in order to obtain the three functions. Throughout this exercise, all the distributions and densities in red tones represent the NBA and the blue tones represent the ACB.

The prior distribution can be obtained by simulating a Gamma distribution $Gamma(800,4)$ for the NBA and a $Gamma(760,4)$ for the ACB.

```{r}
# Prior densities
prior_nba <- c(800,4)
prior_acb <- c(760,4)

sim_nba <- rgamma(100000, shape = prior_nba[1], rate = prior_nba[2])
sim_acb <- rgamma(100000, shape = prior_acb[1], rate = prior_acb[2])

# Plots
ggplot() +
  geom_density(aes(sim_nba),fill="red",alpha=0.5)+
  geom_density(aes(sim_acb), fill="blue",alpha=0.5)+
  labs(x="Scoring",y="Density")
```
In order to plot the likelihood function, we first need to store the data and then use it to estimate the likelihood function through simulation in each case. As we stated, this function would be obtained from a $Poiss(\lambda_{nba})$ for the NBA and from a $Poiss(\lambda_{acb})$ for the ACB. We scale these functions in order to be integrate to 1 (become a density) and plot them.

```{r}
# Store the data
basquet <- read.csv("~/Downloads/basquet.txt", sep="")
y_nba <- basquet$nba
y_acb <- basquet$acb

# Create values of lambda an represent the data in the likelihood density
delta <- 0.01
lambda <- seq(100,300,delta)
lik_nba <- map_dbl(lambda, ~ prod(dpois(y_nba, .x)))
lik_acb <- map_dbl(lambda, ~ prod(dpois(y_acb, .x)))
df_nba<- tibble(lambda,lik_nba)
df_acb<- tibble(lambda,lik_acb)

# Standardize likelihood
coef_nba <- sum(lik_nba)*delta
df_nba$lik_nba <- (df_nba$lik_nba)/coef_nba
coef_acb <- sum(lik_acb)*delta
df_acb$lik_acb <- (df_acb$lik_acb)/coef_acb

# Plot likelihood
ggplot() +
  geom_line(aes(df_nba$lambda,df_nba$lik_nba),col="pink")+
   geom_line(aes(df_acb$lambda,df_acb$lik_acb),col="skyblue")+
  labs(x="Scoring",y="Likelihood")
```

Then, to calculate the posterior distribution, we use the same simulation method as before but updating the parameters. Because the Gamma distribution is a conjugate for the Poisson, one can prove that the resulting posterior would be a $Gamma(\alpha+\sum_y{y_i},\beta+n)$, so we can simulate this distribution for both the NBA and the ACB to obtain the densities.

```{r}
# Compute posterior
n <- length(y_nba)
post_nba <- c(prior_nba[1] + sum(y_nba), prior_nba[2] + n)
post_acb <- c(prior_acb[1] + sum(y_acb), prior_acb[2] + n)

l_post_sim_nba <- rgamma(10000, shape = post_nba[1], rate = post_nba[2])
l_post_sim_acb <- rgamma(10000, shape = post_acb[1], rate = post_acb[2])

ggplot() +
  geom_density(aes(l_post_sim_nba),fill="darkred",alpha=0.5)+
  geom_density(aes(l_post_sim_acb),fill="darkblue",alpha=0.5,)+
  labs(x="Scoring",y="Density")
```

Finally, we can plot the three densities for each case in the same graph:

```{r}
# Plot the three densities
df_nba <- df_nba%>% 
    mutate(
      prior = dgamma(lambda, shape = prior_nba[1], rate = prior_nba[2]),
      product = prior * lik_nba,
      posterior = product / (sum(product)*0.01))

df_acb <- df_acb%>% 
    mutate(
      prior = dgamma(lambda, shape = prior_acb[1], rate = prior_acb[2]),
      product = prior * lik_acb,
      posterior = product / (sum(product)*0.01))

all_nba <- ggplot(df_nba, aes(x=lambda)) +
  geom_line(aes(y=prior, color="Prior")) +
  geom_line(aes(y=lik_nba, color = "Likelihood")) +
  geom_line(aes(y= posterior, color = "Posterior"))+
  labs(x="Scoring",y="Density",color="Legend",title = "NBA")+
  scale_color_manual(values=c("pink", "darkred", "red"))

all_acb <- ggplot(df_acb, aes(x=lambda)) +
  geom_line(aes(y=prior, color="Prior")) +
  geom_line(aes(y=lik_acb, color = "Likelihood")) +
  geom_line(aes(y= posterior, color = "Posterior"))+
  labs(x="Scoring",y="Density",color="Legend",title = "ACB")+
  scale_color_manual(values=c("skyblue", "darkblue", "blue"))

grid.arrange(all_nba, all_acb, ncol = 1)

```
Hence, this is the final result we are asked to plot.

#### 3) What is the probability that more points will be scored in a randomly selected match of the Spanish league than in a randomly selected match of the NBA league?

We are asked to compute $P(y_{acb}>y_{nba})$. In order to compute the probability, we can use the negative binomial (which is the posterior predictive distribution for this case) or we can use simulation through simulating the posterior predictive distribution.

We choose the second option, so we must first obtain both posterior predictive distributions. As before, the red color indicates NBA and the blue color indicates ACB.

```{r}
# Simulate posterior predictive distribution
y_sim_nba <- rpois(10000, l_post_sim_nba)
y_sim_acb <- rpois(10000, l_post_sim_acb)

ggplot() +
  geom_bar(aes(y_sim_nba),fill="darkred",alpha=0.5)+
  geom_bar(aes(y_sim_acb),fill="darkblue",alpha=0.5)+
  labs(x="Scoring",y="Counts")
```

Now, we can just obtain the desired probability by using the mean function:

```{r}
# Compute the probability
mean(y_sim_acb>y_sim_nba)
```

Hence, the probability is approximately $0.136$.

#### 4) What is the probability that the points scored in a NBA match will be 60 points or more larger than the points scored in an ACB match?

Now, we are asked to compute $P(y_{nba}-y_{acb}\geq60)$, as we are asked for the probability of a random NBA match obtaining a difference of 60 or more points respect to a random ACB match. We use the same approach that before, but we just need to use the posterior predictive distributions computed earlier.

```{r}
# Compute the probability
mean(y_sim_nba-y_sim_acb >= 60)
```

Hence, the probability is approximately $0.027$.